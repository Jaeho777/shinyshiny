import os, io, re, time, math, random, threading, zipfile, unicodedata
from datetime import datetime, timedelta
from xml.etree import ElementTree as ET
from concurrent.futures import ThreadPoolExecutor, as_completed

import numpy as np
import pandas as pd
import plotly.express as px
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import streamlit as st
from prophet import Prophet

# ---- requests_cache: optional ----
try:
    import requests_cache
    HAS_REQUESTS_CACHE = True
except Exception:
    requests_cache = None
    HAS_REQUESTS_CACHE = False

# -------------------------------
# App config
# -------------------------------
st.set_page_config(page_title="ì¬ë¬´ ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")

# --- UX ê°œì„ : Professional-looking CSS to hide footer and menu ---
st.markdown("""
    <style>
        /* "Made with Streamlit" í‘¸í„° ìˆ¨ê¸°ê¸° */
        footer {visibility: hidden;}
        /* Streamlit ë©”ì¸ ë©”ë‰´(í–„ë²„ê±° ë²„íŠ¼) ìˆ¨ê¸°ê¸° */
        #MainMenu {visibility: hidden;}
        /* ì»¨í…Œì´ë„ˆ ê°„ ê°„ê²© ì¶”ê°€ */
        .st-emotion-cache-1jicfl2 { 
            margin-bottom: 15px;
        }
    </style>
""", unsafe_allow_html=True)

# --- [v4.0] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "data_loaded" not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.df_all = pd.DataFrame()
    st.session_state.df_dart = pd.DataFrame()
    st.session_state.df_my_company = pd.DataFrame()
    st.session_state.name_dart = ""
    st.session_state.name_my_company = "My Company"
    st.session_state.forecast_y = 3
    st.session_state.lenient_skips = {}
# --- ì„¸ì…˜ ì´ˆê¸°í™” ë ---

# [v4.8] í†µí•© íƒ€ì´í‹€
st.title("ğŸ“Š 1:1 ì¬ë¬´ ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ì‹œë³´ë“œ (v4.8)")
st.caption("(ìƒì¥ì‚¬ 1ê³³) vs. (ë‚´ ê°€ê²Œì˜ ì—°ë„ë³„ 'ê¸°ì´ˆ' ë°ì´í„°) ë¹„êµ")


# -------------------------------
# [v0.0] DART ê´€ë ¨ Helper Functions
# (DART API í‚¤ ë¡œë“œ, HTTP ì„¸ì…˜, DART ë°ì´í„° íŒŒì‹±, ê¸°ì—… ê²€ìƒ‰ ë“±)
# -------------------------------
def load_api_key() -> str | None:
    key = os.getenv("DART_API_KEY")
    if key: return key
    try:
        from dotenv import load_dotenv
        load_dotenv()
        key = os.getenv("DART_API_KEY")
        if key: return key
    except Exception: pass
    import os.path as _p
    cand_paths = [
        _p.expanduser("~/.streamlit/secrets.toml"),
        _p.join(os.getcwd(), ".streamlit", "secrets.toml"),
    ]
    if any(_p.exists(p) for p in cand_paths):
        try: return st.secrets["DART_API_KEY"]
        except Exception: pass
    return None

def _make_session():
    s = requests.Session()
    retry = Retry(
        total=5, backoff_factor=0.6,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"]
    )
    s.mount("https://", HTTPAdapter(max_retries=retry))
    return s

SESSION = _make_session()
RATE_LOCK = threading.Lock()
LAST_CALL = [0.0]
MIN_SPACING = 0.15

def http_get(url, params=None, timeout=40):
    with RATE_LOCK:
        dt = time.time() - LAST_CALL[0]
        if dt < MIN_SPACING:
            time.sleep(MIN_SPACING - dt)
        LAST_CALL[0] = time.time()
    r = SESSION.get(url, params=params, timeout=timeout)
    if r.status_code == 429:
        wait = int(r.headers.get("Retry-After", 2))
        time.sleep(wait + random.uniform(0, 0.5))
        r = SESSION.get(url, params=params, timeout=timeout)
    r.raise_for_status()
    return r

if HAS_REQUESTS_CACHE:
    requests_cache.install_cache("dart_cache", expire_after=60 * 60 * 12)

def fetch_corp_codes_cached(api_key: str) -> pd.DataFrame:
    url = f"https://opendart.fss.or.kr/api/corpCode.xml?crtfc_key={api_key}"
    resp_bytes = http_get(url, timeout=40).content
    with zipfile.ZipFile(io.BytesIO(resp_bytes)) as zf:
        xml_name = None
        for name in zf.namelist():
            lower = name.lower()
            if lower.endswith("corpcode.xml") or lower.endswith("coropcode.xml"):
                xml_name = name; break
        if xml_name is None:
            if "CORPCODE.xml" in zf.namelist(): xml_name = "CORPCODE.xml"
            else: raise RuntimeError(f"CORPCODE.xmlì„ ZIPì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. namelist={zf.namelist()}")
        with zf.open(xml_name) as f:
            tree = ET.parse(f)
    corp_code_list, corp_name_list, stock_code_list = [], [], []
    for el in tree.iterfind(".//list"):
        corp_code_list.append(el.findtext("corp_code") or "")
        corp_name_list.append(el.findtext("corp_name") or "")
        stock_code_list.append(el.findtext("stock_code") or "")
    if not corp_code_list: raise RuntimeError("CORPCODE.xml íŒŒì‹± ê²°ê³¼ 0í–‰")
    df = pd.DataFrame({
        "corp_code": [str(x) for x in corp_code_list],
        "corp_name": [str(x) for x in corp_name_list],
        "stock_code": [str(x) for x in stock_code_list],
    })
    try: df.to_csv("corp_codes.csv", index=False, encoding="utf-8")
    except Exception: pass
    return df

def get_corp_codes(api_key: str) -> pd.DataFrame:
    base_cols = ["corp_code", "corp_name", "stock_code"]
    try:
        df = pd.read_csv("corp_codes.csv", dtype=str, encoding="utf-8")
        for c in base_cols:
            if c not in df.columns: df[c] = ""
        return df[base_cols]
    except Exception: pass
    try:
        df = pd.read_parquet("corp_codes.parquet")
        for c in base_cols:
            if c not in df.columns: df[c] = ""
            else: df[c] = df[c].astype(str)
        return df[base_cols]
    except Exception: pass
    df = fetch_corp_codes_cached(api_key)
    for c in base_cols:
        if c not in df.columns: df[c] = ""
        else: df[c] = df[c].astype(str)
    return df[base_cols]

def _norm(s: str) -> str:
    if s is None: return ""
    s = str(s); s = unicodedata.normalize("NFKC", s)
    s = re.sub(r"[\s\-\_\.\&\/\(\)\[\]\,\+]+", "", s).lower()
    s = s.replace("ì£¼ì‹íšŒì‚¬", "").replace("(ì£¼)", "").replace("ãˆœ", "")
    return s
ALIAS_MAP = {"f&f": "ì—í”„ì•¤ì—f", "ff": "ì—í”„ì•¤ì—f", "fnf": "ì—í”„ì•¤ì—í”„", "thehandsome": "í•œì„¬", "handsome": "í•œì„¬", "shinsegaeinternational": "ì‹ ì„¸ê³„ì¸í„°ë‚´ì…”ë‚ ", "shinsegaeintl": "ì‹ ì„¸ê³„ì¸í„°ë‚´ì…”ë‚ ", "kolonindustries": "ì½”ì˜¤ë¡±ì¸ë”ìŠ¤íŠ¸ë¦¬",}
def _alias_to_kor(q_norm: str): return ALIAS_MAP.get(q_norm)
def _and_contains(series: pd.Series, tokens: list[str]) -> pd.Series:
    norm_series = series.fillna("").astype(str).apply(_norm)
    mask = pd.Series([True] * len(norm_series), index=norm_series.index)
    for t in tokens:
        if not t: continue
        mask = mask & norm_series.str.contains(re.escape(t))
    return mask
def search_corp_smart(corp_df: pd.DataFrame, query: str, limit: int = 30) -> pd.DataFrame:
    if not query: return corp_df.head(limit)
    q = query.strip(); q_norm = _norm(q)
    if re.fullmatch(r"\d{6}", q):
        hit = corp_df.loc[corp_df["stock_code"] == q]
        if not hit.empty: return hit.head(limit)
    alias = _alias_to_kor(q_norm); tokens = []
    if alias: tokens = [_norm(alias)]
    else: tokens = [_norm(tok) for tok in re.split(r"\s+", q) if tok.strip()]
    mask_name = _and_contains(corp_df["corp_name"], tokens); res = corp_df[mask_name]
    if not res.empty: return res.head(limit)
    if "stock_name" in corp_df.columns:
        mask_stockname = _and_contains(corp_df["stock_name"], tokens); res2 = corp_df[mask_stockname]
        if not res2.empty: return res2.head(limit)
    loose = corp_df[corp_df["corp_name"].astype(str).str.contains(query, case=False, na=False) | (corp_df["stock_name"].astype(str).str.contains(query, case=False, na=False) if "stock_name" in corp_df.columns else False)]
    return loose.head(limit)

def to_num_safe(x):
    try: return float(str(x).replace(",", ""))
    except Exception: return None
ACCOUNT_EXACT = {"INVENTORY": ["ì¬ê³ ìì‚°"],"SALES": ["ë§¤ì¶œì•¡", "ë§¤ì¶œì•¡(ìˆ˜ìµ)"],"COGS": ["ë§¤ì¶œì›ê°€"],"TOTAL_ASSETS": ["ìì‚°ì´ê³„", "ì´ìì‚°"],"NET_INCOME": ["ë‹¹ê¸°ìˆœì´ìµ", "ë‹¹ê¸°ìˆœì´ìµ(ì†ì‹¤)", "ì§€ë°°ê¸°ì—…ì˜ì†Œìœ ì£¼ì§€ë¶„ì—ê·€ì†ë˜ëŠ”ë‹¹ê¸°ìˆœì´ìµ"],"GROSS_PROFIT": ["ë§¤ì¶œì´ì´ìµ", "ë§¤ì¶œì´ì´ìµ(ì†ì‹¤)"],"TOTAL_REVENUE": ["ì˜ì—…ìˆ˜ìµ", "ìˆ˜ìµ", "ë§¤ì¶œì•¡(ì˜ì—…ìˆ˜ìµ)"],"COMPREHENSIVE_INCOME": ["ì´í¬ê´„ì†ìµ", "ë‹¹ê¸°ì´í¬ê´„ì†ìµ"]}
ACCOUNT_CONTAINS = {"INVENTORY_PARTS": ["ìƒí’ˆ", "ì œí’ˆ", "ë°˜ì œí’ˆ", "ì¬ê³µí’ˆ", "ì›ì¬ë£Œ", "ì €ì¥í’ˆ"],"SALES": ["ë§¤ì¶œ", "ìˆ˜ìµ"],"NET_INCOME": ["ë‹¹ê¸°ìˆœì´ìµ", "ì§€ë°°ê¸°ì—…", "ìˆœì´ìµ"],"TOTAL_ASSETS": ["ìì‚°ì´ê³„", "ì´ìì‚°"],"COGS": ["ë§¤ì¶œì›ê°€"]}
ACCOUNT_IDS = {"INVENTORY": ["ifrs-full_Inventories", "ifrs_Inventories"],"TOTAL_ASSETS": ["ifrs-full_Assets", "ifrs_Assets"],"NET_INCOME": ["ifrs-ProfitLoss", "ifrs-full_ProfitLoss"],"SALES": ["ifrs-Revenue", "ifrs-full_Revenue"],"COGS": ["dart_CostOfSales"]}
def pick_first_exact(df, names):
    for nm in names:
        hit = df.loc[df["account_nm"] == nm]
        if not hit.empty: return to_num_safe(hit["thstrm_amount"].iloc[0])
    return None
def pick_by_contains(df, substr_list):
    cand = df[df["account_nm"].apply(lambda s: any(ss in str(s) for ss in substr_list))]
    if cand.empty: return None
    vals = cand["thstrm_amount"].apply(to_num_safe).dropna()
    if vals.empty: return None
    return float(vals.iloc[vals.abs().argmax()])
def pick_by_ids(df, id_list):
    if "account_id" not in df.columns or not id_list: return None
    cand = df[df["account_id"].isin(id_list)]
    if cand.empty: return None
    return to_num_safe(cand["thstrm_amount"].iloc[0])
def inventory_from_parts(df):
    parts = []
    for part in ACCOUNT_CONTAINS["INVENTORY_PARTS"]:
        sub = df[df["account_nm"] == part]
        if sub.empty: sub = df[df["account_nm"].astype(str).str.contains(part)]
        if not sub.empty:
            v = to_num_safe(sub["thstrm_amount"].iloc[0])
            if v is not None: parts.append(v)
    return sum(parts) if parts else None
def get_accounts(api_key: str, corp_code: str, year: int, fs_div: str, rc: str) -> pd.DataFrame:
    url = "https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json"
    params = {"crtfc_key": api_key, "corp_code": corp_code, "bsns_year": str(year), "reprt_code": rc, "fs_div": fs_div}
    data = http_get(url, params=params, timeout=40).json()
    if data.get("status") == "000":
        df = pd.DataFrame(data.get("list", []))
        if "thstrm_amount" in df.columns: df["thstrm_amount"] = df["thstrm_amount"].fillna("0")
        for c in ["account_nm", "account_id", "thstrm_amount"]:
            if c not in df.columns: df[c] = None
        return df
    return pd.DataFrame()
def fetch_year_block(api_key, corp_code, year):
    reprt_codes = ["11011", "11014", "11012", "11013"]
    fs_divs = ["CFS", "OFS"]
    for rc in reprt_codes:
        for fs in fs_divs:
            df = get_accounts(api_key, corp_code, year, fs, rc)
            if not df.empty: return (year, df)
    return (year, pd.DataFrame())
def fetch_panel_parallel(api_key: str, corp_code: str, years: list, max_workers: int = 4) -> dict[int, pd.DataFrame]:
    out = {}
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(fetch_year_block, api_key, corp_code, y): y for y in years}
        for fut in as_completed(futs):
            y, df = fut.result()
            out[y] = df
    return out
def extract_metrics(year_df_map: dict[int, pd.DataFrame], years: list, strict: bool = True):
    rows = []; skipped = []
    for y in years:
        got = year_df_map.get(y, pd.DataFrame())
        if got.empty:
            msg = f"[OpenDART] {y}ë…„ ë°ì´í„° ì—†ìŒ"
            if strict: raise ValueError(msg)
            skipped.append((y, msg)); continue
        inv = (pick_first_exact(got, ACCOUNT_EXACT["INVENTORY"]) or pick_by_ids(got, ACCOUNT_IDS.get("INVENTORY", [])) or inventory_from_parts(got))
        sales = (pick_first_exact(got, ACCOUNT_EXACT["SALES"]) or pick_by_ids(got, ACCOUNT_IDS.get("SALES", [])) or pick_first_exact(got, ACCOUNT_EXACT["TOTAL_REVENUE"]) or pick_by_contains(got, ACCOUNT_CONTAINS["SALES"]))
        cogs = (pick_first_exact(got, ACCOUNT_EXACT.get("COGS", [])) or pick_by_contains(got, ACCOUNT_CONTAINS["COGS"]))
        assets = (pick_first_exact(got, ACCOUNT_EXACT["TOTAL_ASSETS"]) or pick_by_ids(got, ACCOUNT_IDS.get("TOTAL_ASSETS", [])) or pick_by_contains(got, ACCOUNT_CONTAINS["TOTAL_ASSETS"]))
        ni = (pick_first_exact(got, ACCOUNT_EXACT["NET_INCOME"]) or pick_by_ids(got, ACCOUNT_IDS.get("NET_INCOME", [])) or pick_by_contains(got, ACCOUNT_CONTAINS["NET_INCOME"]) or pick_first_exact(got, ACCOUNT_EXACT["COMPREHENSIVE_INCOME"]))
        gp = pick_first_exact(got, ACCOUNT_EXACT["GROSS_PROFIT"])
        core_ok = (assets is not None) and (ni is not None) and (inv is not None) and ((sales is not None) or (cogs is not None))
        if not core_ok:
            msg = f"[OpenDART] {y}ë…„ í•µì‹¬ ê³„ì • ëˆ„ë½"
            if strict: raise ValueError(msg)
            skipped.append((y, msg)); continue
        roa = (ni / assets) * 100.0 if assets else None
        inv_turn = (cogs / inv) if (cogs is not None and inv) else ((sales / inv) if (sales is not None and inv) else None)
        gp_margin = (gp / sales * 100.0) if (gp is not None and sales not in (None, 0)) else None
        rows.append({"Year": y, "ì¬ê³ ìì‚°": inv, "ë§¤ì¶œì•¡": sales, "ë§¤ì¶œì´ì´ìµ": gp, "ë§¤ì¶œì´ì´ìµë¥ (%)": gp_margin, "ìì‚°ì´ê³„": assets, "ë‹¹ê¸°ìˆœì´ìµ": ni, "ROA(%)": roa, "ì¬ê³ íšŒì „ìœ¨": inv_turn})
    base_cols = ["Year", "ì¬ê³ ìì‚°", "ë§¤ì¶œì•¡", "ë§¤ì¶œì´ì´ìµ", "ë§¤ì¶œì´ì´ìµë¥ (%)", "ìì‚°ì´ê³„", "ë‹¹ê¸°ìˆœì´ìµ", "ROA(%)", "ì¬ê³ íšŒì „ìœ¨", "Date"]
    if len(rows) == 0:
        if strict: raise ValueError("ì„ íƒí•œ êµ¬ê°„ì—ì„œ ìœ íš¨í•œ ì—°ë„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(columns=base_cols), skipped
    df = pd.DataFrame(rows)
    if "Year" in df.columns: df = df.sort_values("Year")
    df["Date"] = pd.to_datetime(df["Year"].astype(int).astype(str) + "-12-31", errors="coerce")
    need = ["Year", "Date", "ì¬ê³ ìì‚°", "ìì‚°ì´ê³„", "ë‹¹ê¸°ìˆœì´ìµ", "ROA(%)", "ì¬ê³ íšŒì „ìœ¨"]
    if strict and df[need].isna().any().any():
        bad = df[df[need].isna().any(axis=1)]["Year"].tolist()
        raise ValueError(f"[ê²€ì¦ ì‹¤íŒ¨] í•„ìˆ˜ ì§€í‘œ ë¯¸ì‚°ì¶œ ì—°ë„: {bad}")
    if strict:
        return df, []
    else:
        df = df.dropna(subset=["ì¬ê³ ìì‚°", "ìì‚°ì´ê³„", "ë‹¹ê¸°ìˆœì´ìµ", "ROA(%)", "ì¬ê³ íšŒì „ìœ¨"])
        return df, skipped
# --- [v0.0] DART í•¨ìˆ˜ ë ---


# --- [v3.0] SKU/íŒŒì¼ ê´€ë ¨ Helper Function ---
def find_best_match(column_list, keywords):
    norm = lambda s: str(s).lower().replace("_", "").replace(" ", "")
    for col in column_list:
        norm_col = norm(col)
        if norm_col in keywords:
            return col
    for keyword in keywords:
        for col in column_list:
            if keyword in norm(col):
                return col
    return ""
# --- [v3.0] SKU í•¨ìˆ˜ ë ---


# -------------------------------
# [v4.1] Sidebar (ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •) - "ê³„ì‚°" ê¸°ëŠ¥ ì¶”ê°€
# -------------------------------
st.sidebar.header("ğŸ“Š 1:1 ë¹„êµ ë°ì´í„° ì„¤ì •")

# --- [v4.0] ë°ì´í„° ì†ŒìŠ¤ 1: DART ---
st.sidebar.subheader("ë°ì´í„° ì†ŒìŠ¤ 1: ìƒì¥ì‚¬ (DART)")
API_KEY_DART = load_api_key()

if not API_KEY_DART:
    st.sidebar.error(
        "OpenDART API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        "ìƒì¥ì‚¬ ë¹„êµë¥¼ ìœ„í•´ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
        "(í™˜ê²½ë³€ìˆ˜, .env, .streamlit/secrets.toml ì¤‘ í•˜ë‚˜ì— 'DART_API_KEY' ì„¤ì •)"
    )
    corp_df = pd.DataFrame() # ë¹ˆ DFë¡œ ì„¤ì •
else:
    try:
        with st.spinner("ê¸°ì—… ì½”ë“œ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            corp_df = get_corp_codes(API_KEY_DART)
    except Exception as e:
        st.sidebar.error(f"ê¸°ì—… ì½”ë“œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        corp_df = pd.DataFrame()

if 'corp_df' not in locals() or corp_df.empty:
    st.sidebar.warning("DART ê¸°ì—… ì½”ë“œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì–´ ìƒì¥ì‚¬ ì„ íƒì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
    name1_dart = ""
    code1 = ""
else:
    q1 = st.sidebar.text_input("ë¹„êµí•  ìƒì¥ì‚¬ 1ê³³ ê²€ìƒ‰ (ì˜ˆ: í•œì„¬)", "í•œì„¬")
    cand1 = search_corp_smart(corp_df, q1, limit=30)
    if cand1.empty:
        st.sidebar.error("ê¸°ì—… ê²€ìƒ‰ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        name1_dart = ""
        code1 = ""
    else:
        def _label(row):
            code = row.get("stock_code", "")
            stock = row.get("stock_name", "")
            parts = [row["corp_name"]]
            if code: parts.append(f"[{code}]")
            if stock: parts.append(f"- {stock}")
            return " ".join(parts)
        sel1 = st.sidebar.selectbox("ìƒì¥ì‚¬ ì„ íƒ", options=cand1.index.tolist(), format_func=lambda i: _label(cand1.loc[i]))
        code1 = cand1.loc[sel1, "corp_code"]
        name1_dart = cand1.loc[sel1, "corp_name"]

# --- [v4.1] ë°ì´í„° ì†ŒìŠ¤ 2: My Company (íŒŒì¼ ì—…ë¡œë“œ) ---
st.sidebar.subheader("ë°ì´í„° ì†ŒìŠ¤ 2: ë‚´ ê°€ê²Œ (íŒŒì¼)")
name_my_company = st.sidebar.text_input("ë‚´ ê°€ê²Œ ì´ë¦„", "My Company")
file_data_my = st.sidebar.file_uploader("ë‚´ ê°€ê²Œì˜ 'ì—°ë„ë³„ ê¸°ì´ˆ' ë°ì´í„° íŒŒì¼ (CSV/Excel)", type=["csv", "xlsx"])

# [v4.1] 'ìŠ¤ë§ˆíŠ¸ ì—´ ì¶”ì²œ'ì„ ìœ„í•œ ì—´ ë§¤í•‘ (ê¸°ì´ˆ ë°ì´í„°)
guess_year, guess_inv, guess_sales, guess_gp, guess_cogs, guess_ni, guess_assets = "", "", "", "", "", "", ""
df_preview_my = None

if file_data_my:
    try:
        file_buffer = io.BytesIO(file_data_my.read())
        if file_data_my.name.endswith('.csv'):
            df_preview_my = pd.read_csv(file_buffer, nrows=10)
        else:
            df_preview_my = pd.read_excel(file_buffer, nrows=10)
        file_data_my.seek(0)
        all_columns = df_preview_my.columns.tolist()

        YEAR_KEYWORDS = ['year', 'ì—°ë„', 'yr', 'ì—°']
        INV_KEYWORDS = ['ì¬ê³ ìì‚°', 'inventory', 'stock_value', 'inv']
        SALES_KEYWORDS = ['ë§¤ì¶œì•¡', 'sales', 'revenue']
        # [v4.4] GP í‚¤ì›Œë“œ ìˆ˜ì • (COGSì™€ ê²¹ì¹  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        GP_KEYWORDS = ['ë§¤ì¶œì´ì´ìµ', 'gross_profit', 'gp']
        # [v4.1] ë¹„ìœ¨ ê³„ì‚°ì„ ìœ„í•œ 'ê¸°ì´ˆ' ë°ì´í„° í‚¤ì›Œë“œ
        COGS_KEYWORDS = ['ë§¤ì¶œì›ê°€', 'cogs', 'cost_of_goods_sold']
        NI_KEYWORDS = ['ë‹¹ê¸°ìˆœì´ìµ', 'net_income', 'ni']
        ASSETS_KEYWORDS = ['ìì‚°ì´ê³„', 'total_assets', 'assets']
        
        guess_year = find_best_match(all_columns, YEAR_KEYWORDS)
        guess_inv = find_best_match(all_columns, INV_KEYWORDS)
        guess_sales = find_best_match(all_columns, SALES_KEYWORDS)
        guess_gp = find_best_match(all_columns, GP_KEYWORDS)
        guess_cogs = find_best_match(all_columns, COGS_KEYWORDS)
        guess_ni = find_best_match(all_columns, NI_KEYWORDS)
        guess_assets = find_best_match(all_columns, ASSETS_KEYWORDS)
        
    except Exception as e:
        st.sidebar.error(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        file_data_my = None

st.sidebar.info("íŒŒì¼ì˜ 'ì—°ë„(Year)' ì—´ì€ í•„ìˆ˜ì…ë‹ˆë‹¤. ë¹„ìœ¨ ê³„ì‚°ì„ ìœ„í•´ 'ê¸°ì´ˆ' ë°ì´í„° ì—´ì„ ë§¤í•‘í•˜ì„¸ìš”.")

with st.sidebar.expander("ë‚´ ê°€ê²Œ íŒŒì¼ 'ì—´(Column)' ë§¤í•‘í•˜ê¸°", expanded=(file_data_my is not None)):
    if df_preview_my is not None:
        st.dataframe(df_preview_my.head(3), use_container_width=True)
        st.caption("â¬†ï¸ ìë™ ê°ì§€ë¥¼ ìœ„í•´ íŒŒì¼ ìƒìœ„ 3ì¤„ì„ ë¯¸ë¦¬ ë´…ë‹ˆë‹¤.")
        
    st.markdown("**(í•„ìˆ˜) ê³µí†µ**")
    col_my_year = st.text_input("ì—°ë„ (Year) ì—´", value=guess_year)
    
    st.markdown("**(í•„ìˆ˜) ì°¨íŠ¸ 1, 3ìš©**")
    col_my_inv = st.text_input("ì¬ê³ ìì‚° ì—´", value=guess_inv)
    col_my_sales = st.text_input("ë§¤ì¶œì•¡ ì—´", value=guess_sales)
    
    st.markdown("**(í•„ìˆ˜) ì°¨íŠ¸ 2ìš© (ë¹„ìœ¨ ê³„ì‚°)**")
    col_my_cogs = st.text_input("ë§¤ì¶œì›ê°€ (COGS) ì—´", value=guess_cogs)
    col_my_net_income = st.text_input("ë‹¹ê¸°ìˆœì´ìµ (NI) ì—´", value=guess_ni)
    col_my_total_assets = st.text_input("ìì‚°ì´ê³„ (Assets) ì—´", value=guess_assets)
    # [v4.4] ë§¤ì¶œì´ì´ìµì€ ì´ì œ 'ì„ íƒ' ì‚¬í•­. ì—†ìœ¼ë©´ ìë™ ê³„ì‚°ë¨.
    col_my_gp = st.text_input("ë§¤ì¶œì´ì´ìµ (GP) ì—´ (ì„ íƒ)", value=guess_gp)

# --- [v4.0] ê³µí†µ ì„¤ì • ---
st.sidebar.subheader("ê³µí†µ ë¶„ì„ ì„¤ì •")
year_start, year_end = st.sidebar.select_slider(
    "ë¶„ì„ ì—°ë„ êµ¬ê°„",
    options=list(range(2015, datetime.now().year + 1)),
    value=(2019, max(2019, datetime.now().year - 1))
)
YEARS = list(range(year_start, year_end + 1))

lenient = st.sidebar.checkbox(
    "Lenient ëª¨ë“œ (DART ê²°ì¸¡ ì—°ë„ ì œì™¸)",
    value=False,
    help="DART ë°ì´í„° ìˆ˜ì§‘ ì‹œ ê²°ì¸¡ ì—°ë„ê°€ ìˆì–´ë„ ì¤‘ë‹¨í•˜ì§€ ì•Šê³  ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤."
)

forecast_y = st.sidebar.slider(
    "ì˜ˆì¸¡ ì—°ë„ ìˆ˜ (ë¯¸ë˜)", 
    1, 5, 3, 
    help="[ì¬ê³  ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤] íƒ­ì—ì„œ ì‚¬ìš©í•  ë¯¸ë˜ ì˜ˆì¸¡ ì—°ë„ ìˆ˜ì…ë‹ˆë‹¤."
)

st.sidebar.markdown("---")

# --- [v4.4] ë°ì´í„° ë¡œë“œ ë²„íŠ¼ (GP ê³„ì‚° ë¡œì§ ì¶”ê°€) ---
if st.sidebar.button("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¹„êµ", type="primary"):
    df_dart = pd.DataFrame()
    df_my_company = pd.DataFrame()
    
    # 1. DART ë°ì´í„° ë¡œë“œ
    if not code1 or not API_KEY_DART:
        st.sidebar.warning("DART ìƒì¥ì‚¬ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ê±°ë‚˜ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        try:
            with st.spinner(f"{name1_dart} DART ë°ì´í„° ìˆ˜ì§‘/ê°€ê³µ ì¤‘..."):
                year_map1 = fetch_panel_parallel(API_KEY_DART, code1, YEARS, max_workers=4)
                df_dart, skips1 = extract_metrics(year_map1, YEARS, strict=(not lenient))
                
                if df_dart.empty:
                    st.sidebar.error(f"{name1_dart}ì˜ DART ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    df_dart["ë¸Œëœë“œ"] = name1_dart
                    st.session_state.lenient_skips = {'skip1': skips1}
                    st.session_state.df_dart = df_dart
                    st.session_state.name_dart = name1_dart

        except Exception as e:
            st.error(f"DART ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # 2. 'ë‚´ ê°€ê²Œ' ë°ì´í„° ë¡œë“œ ë° 'ê³„ì‚°'
    if not file_data_my:
        st.sidebar.warning("'ë‚´ ê°€ê²Œ' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    elif not col_my_year:
        st.sidebar.error("'ë‚´ ê°€ê²Œ' íŒŒì¼ì˜ 'ì—°ë„ (Year)' ì—´ì„ ë°˜ë“œì‹œ ë§¤í•‘í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        try:
            with st.spinner(f"'{name_my_company}' íŒŒì¼ ë°ì´í„° ê°€ê³µ ë° 'ë¹„ìœ¨ ê³„ì‚°' ì¤‘..."):
                df_upload = pd.read_csv(file_data_my) if file_data_my.name.endswith('.csv') else pd.read_excel(file_data_my)
                
                # [v4.1] í•„ìš”í•œ 'ê¸°ì´ˆ' ì—´ë§Œ ë§¤í•‘
                df_my = pd.DataFrame()
                
                # 'ì—°ë„'ëŠ” í•„ìˆ˜
                df_my["Year"] = pd.to_numeric(df_upload[col_my_year], errors='coerce')

                # [v4.4] ê¸°ì´ˆ ë°ì´í„° ë§¤í•‘
                base_map_dict = {
                    "ì¬ê³ ìì‚°": col_my_inv,
                    "ë§¤ì¶œì•¡": col_my_sales,
                    "COGS": col_my_cogs,
                    "NI": col_my_net_income,
                    "Assets": col_my_total_assets,
                    "ë§¤ì¶œì´ì´ìµ": col_my_gp # [v4.4] GPë„ ì¼ë‹¨ ë§¤í•‘
                }
                
                for key_metric, col_name in base_map_dict.items():
                    if col_name and col_name in df_upload.columns:
                        # [v4.4] GPëŠ” í‚¤ê°€ ê²¹ì¹˜ë¯€ë¡œ .get()ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ
                        if col_name in df_upload:
                            df_my[key_metric] = pd.to_numeric(df_upload.get(col_name), errors='coerce')
                
                df_my = df_my.dropna(subset=["Year"])

                # [v4.4] 'ë¹„ìœ¨' ë° 'GP' ìë™ ê³„ì‚°
                
                # 1. ì¬ê³ íšŒì „ìœ¨ = ë§¤ì¶œì›ê°€ / ì¬ê³ ìì‚°
                if "COGS" in df_my.columns and "ì¬ê³ ìì‚°" in df_my.columns:
                    df_my["ì¬ê³ íšŒì „ìœ¨"] = (df_my["COGS"] / df_my["ì¬ê³ ìì‚°"]).replace([np.inf, -np.inf], np.nan)
                
                # 2. ROA(%) = (ë‹¹ê¸°ìˆœì´ìµ / ìì‚°ì´ê³„) * 100
                if "NI" in df_my.columns and "Assets" in df_my.columns:
                    df_my["ROA(%)"] = (df_my["NI"] / df_my["Assets"] * 100).replace([np.inf, -np.inf], np.nan)
                
                # 3. [v4.4] ë§¤ì¶œì´ì´ìµ (GP)
                # ë§Œì•½ GPê°€ ì´ë¯¸ ë§¤í•‘ë˜ì–´ ìˆì§€ *ì•Šë‹¤ë©´*, 'ë§¤ì¶œì•¡'ê³¼ 'ë§¤ì¶œì›ê°€'ë¡œ ê³„ì‚°
                if "ë§¤ì¶œì´ì´ìµ" not in df_my.columns:
                    if "ë§¤ì¶œì•¡" in df_my.columns and "COGS" in df_my.columns:
                        df_my["ë§¤ì¶œì´ì´ìµ"] = df_my["ë§¤ì¶œì•¡"] - df_my["COGS"]
                        st.sidebar.success("'ë§¤ì¶œì´ì´ìµ' ìë™ ê³„ì‚° ì™„ë£Œ (ë§¤ì¶œì•¡ - ë§¤ì¶œì›ê°€)")
                    
                # DART ë°ì´í„°ì™€ ê³µí†µ ì»¬ëŸ¼ ì„¤ì •
                df_my["Date"] = pd.to_datetime(df_my["Year"].astype(int).astype(str) + "-12-31", errors="coerce")
                df_my["ë¸Œëœë“œ"] = name_my_company
                
                st.session_state.df_my_company = df_my
                st.session_state.name_my_company = name_my_company

        except Exception as e:
            st.error(f"'ë‚´ ê°€ê²Œ' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            st.exception(e) # [v4.4] ë””ë²„ê·¸ë¥¼ ìœ„í•´ ì˜¤ë¥˜ ìƒì„¸ í‘œì‹œ

    # --- [v4.7] ë°ì´í„° í†µí•© ë° ë³´ì • (ë²„ê·¸ ìˆ˜ì •) ---
    df_concat = pd.concat(
        [st.session_state.df_dart, st.session_state.df_my_company], 
        ignore_index=True
    )

    # [v4.7] !!! 4ë¶„ë©´ ì°¨íŠ¸ìš© ë°ì´í„° ë³´ì • (Key Fix) !!!
    # 4ë¶„ë©´ ì°¨íŠ¸ì— í•„ìš”í•œ 6ê°œ ì—´ì„ ì •ì˜
    required_cols_for_plot = [
        "Year", "ë¸Œëœë“œ", "Date", 
        "ì¬ê³ íšŒì „ìœ¨", "ROA(%)", "ë§¤ì¶œì´ì´ìµ", 
        "ì¬ê³ ìì‚°", "ë§¤ì¶œì•¡"
    ]
    
    # 6ê°œ ì—´ì´ ëª¨ë‘ ì¡´ì¬í•˜ë„ë¡ ë³´ì¥ (ì—†ìœ¼ë©´ NaNìœ¼ë¡œ ì±„ì›€)
    for col in required_cols_for_plot:
        if col not in df_concat.columns:
            df_concat[col] = np.nan # ì—´ ìì²´ê°€ ì—†ìœ¼ë©´ NaNìœ¼ë¡œ ìƒì„±

    st.session_state.df_all = df_concat # ë³´ì •ëœ DFë¥¼ ì„¸ì…˜ì— ì €ì¥
    # --- [v4.7] ìˆ˜ì • ë ---
    
    if not st.session_state.df_all.empty:
        st.session_state.data_loaded = True
        st.session_state.forecast_y = forecast_y
        st.success("ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    else:
        st.session_state.data_loaded = False
        st.error("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


# -------------------------------
# [v4.0] ë©”ì¸ íŒ¨ë„
# -------------------------------

if not st.session_state.data_loaded:
    st.markdown("---")
    with st.container(border=True):
        st.header("Welcome to the 1:1 Benchmarking Dashboard!")
        st.write("")
        st.write("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ 'ìƒì¥ì‚¬' 1ê³³ì„ ì„ íƒí•˜ê³ , 'ë‚´ ê°€ê²Œ'ì˜ ì—°ë„ë³„ ë°ì´í„° íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.write("ê·¸ ë‹¤ìŒ [ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë¹„êµ] ë²„íŠ¼ì„ ëˆŒëŸ¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        st.write("")
    st.stop()

# [v4.0] ë°ì´í„° ë¡œë“œ ì™„ë£Œ ì‹œ
df_all = st.session_state.df_all
name1 = st.session_state.name_dart
name2 = st.session_state.name_my_company
forecast_y = st.session_state.forecast_y
skips = st.session_state.lenient_skips.get('skip1', [])

if skips:
    with st.expander(f"LENIENT ëª¨ë“œ: {name1}ì˜ ì¼ë¶€ ì—°ë„ ë°ì´í„°ê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤."):
        st.write(f"â€¢ {name1} ì œì™¸: {skips}")

# --- [v4.0] KPI (ë‘ íšŒì‚¬ ë¹„êµ) ---
st.markdown("---")
with st.container(border=True):
    st.subheader("í•µì‹¬ ì§€í‘œ ìš”ì•½ (ì„ íƒ ê¸°ê°„ í‰ê· )")
    col1, col2 = st.columns(2)
    
    df1 = df_all[df_all["ë¸Œëœë“œ"] == name1]
    df2 = df_all[df_all["ë¸Œëœë“œ"] == name2]
    
    with col1:
        st.markdown(f"#### {name1} (DART)")
        if not df1.empty:
            df1_inv = pd.to_numeric(df1['ì¬ê³ ìì‚°'], errors='coerce').mean()
            df1_roa = pd.to_numeric(df1['ROA(%)'], errors='coerce').mean()
            df1_turn = pd.to_numeric(df1['ì¬ê³ íšŒì „ìœ¨'], errors='coerce').mean()
            st.metric("í‰ê·  ì¬ê³ ìì‚°", f"{int(df1_inv):,} ì›")
            st.metric("í‰ê·  ROA(%)", f"{df1_roa:.2f} %")
            st.metric("í‰ê·  ì¬ê³ íšŒì „ìœ¨", f"{df1_turn:.2f} íšŒ")
        else: st.warning("ë°ì´í„° ì—†ìŒ")
    with col2:
        st.markdown(f"#### {name2} (My Company)")
        if not df2.empty:
            df2_inv = pd.to_numeric(df2['ì¬ê³ ìì‚°'], errors='coerce').mean()
            df2_roa = pd.to_numeric(df2['ROA(%)'], errors='coerce').mean()
            df2_turn = pd.to_numeric(df2['ì¬ê³ íšŒì „ìœ¨'], errors='coerce').mean()
            st.metric("í‰ê·  ì¬ê³ ìì‚°", f"{int(df2_inv):,} ì›" if not pd.isna(df2_inv) else "ë°ì´í„° ì—†ìŒ")
            st.metric("í‰ê·  ROA(%)", f"{df2_roa:.2f} %" if not pd.isna(df2_roa) else "ë°ì´í„° ì—†ìŒ")
            st.metric("í‰ê·  ì¬ê³ íšŒì „ìœ¨", f"{df2_turn:.2f} íšŒ" if not pd.isna(df2_turn) else "ë°ì´í„° ì—†ìŒ")
        else: st.warning("ë°ì´í„° ì—†ìŒ")

# --- [v4.0] ë©”ì¸ íƒ­ (ê¸°ì¡´ íƒ­ 1ì˜ í•˜ìœ„ íƒ­) ---
with st.container(border=True):
    tab1_1, tab1_2, tab1_3 = st.tabs([
        "ì§€í‘œ íƒìƒ‰", 
        "íš¨ìœ¨ì„± vs ìˆ˜ìµì„± (4ë¶„ë©´ ë¶„ì„)", 
        "ì¬ê³  ì˜ˆì¸¡ ì‹œë‚˜ë¦¬ì˜¤"
    ])

    with tab1_1:
        st.subheader("ì§€í‘œ ì¶”ì´ ë¹„êµ")
        # [v4.1] 'ë§¤ì¶œì´ì´ìµ'ë„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ë‚´ ê°€ê²Œ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
        indicator = st.selectbox("ì§€í‘œ ì„ íƒ", ["ì¬ê³ ìì‚°", "ë§¤ì¶œì•¡", "ë§¤ì¶œì´ì´ìµ", "ROA(%)", "ì¬ê³ íšŒì „ìœ¨"], index=0, key="tab1_indicator")
        
        # [v4.2] ë¡œê·¸ ìŠ¤ì¼€ì¼ ì²´í¬ë°•ìŠ¤ ì¶”ê°€
        use_log_scale_tab1 = st.checkbox("ë¡œê·¸ ìŠ¤ì¼€ì¼(Log Scale) ì‚¬ìš© (ê·œëª¨ ì°¨ì´ í´ ë•Œ)", value=True, 
                                         help="ê¸ˆì•¡(ì˜ˆ: ë§¤ì¶œì•¡, ì¬ê³ ìì‚°)ì˜ ê·œëª¨ ì°¨ì´ê°€ ë„ˆë¬´ ì»¤ì„œ ì¶”ì„¸ ë¹„êµê°€ ì–´ë ¤ìš¸ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.",
                                         key="log_scale_tab1")

        # [v4.0] í•´ë‹¹ ì§€í‘œê°€ ì—†ëŠ” íšŒì‚¬ëŠ” ì œì™¸
        chart_df = df_all.dropna(subset=[indicator])
        
        fig1 = px.line(
            chart_df, x="Date", y=indicator, color="ë¸Œëœë“œ", markers=True,
            title=f"{indicator} ì¶”ì´ ({name1} vs {name2})", template="plotly_white"
        )
        
        # [v4.2] ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©
        if use_log_scale_tab1:
            # [v4.4] 0 ë˜ëŠ” ìŒìˆ˜ ê°’ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-except ì¶”ê°€
            try:
                if chart_df[indicator].min() > 0:
                    fig1.update_layout(yaxis_type="log")
                else:
                    st.warning("ë¡œê·¸ ìŠ¤ì¼€ì¼ì€ 0 ë˜ëŠ” ìŒìˆ˜ ê°’ì´ ìˆìœ¼ë©´ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¼ë°˜ ìŠ¤ì¼€ì¼ë¡œ í‘œì‹œ)")
                    fig1.update_layout(yaxis_type="linear")
            except Exception:
                fig1.update_layout(yaxis_type="linear")
        
        st.plotly_chart(fig1, use_container_width=True)
        with st.expander("ë¹„êµ ë°ì´í„° ë³´ê¸°"):
            st.dataframe(chart_df.sort_values(["ë¸Œëœë“œ", "Year"]).reset_index(drop=True), use_container_width=True)
with tab1_2:
    st.subheader("ì¬ê³ íšŒì „ìœ¨ vs ROA (4ë¶„ë©´ ë§¤íŠ¸ë¦­ìŠ¤)")
    st.info(
        """
        ì´ ì°¨íŠ¸ëŠ” **4ë¶„ë©´ ë§¤íŠ¸ë¦­ìŠ¤**ë¡œ, ê¸°ì—…ì˜ ì¬ê³  íš¨ìœ¨ì„±ê³¼ ìˆ˜ìµì„±ì„ í•œëˆˆì— ë³´ì—¬ì¤ë‹ˆë‹¤. 
        ì ì„ ì€ ë‘ ê¸°ì—… ë°ì´í„°ì˜ **í‰ê· **ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        * **Xì¶• (ì¬ê³ íšŒì „ìœ¨):** ë†’ì„ìˆ˜ë¡ 'íš¨ìœ¨ì ' (ë¹¨ë¦¬ íŒë§¤)
        * **Yì¶• (ROA):** ë†’ì„ìˆ˜ë¡ 'ìˆ˜ìµì„±'ì´ ë†’ìŒ
        """
    )
    
    chart_df = df_all.copy()

    # í•„ìˆ˜ ê°’ ì±„ìš°ê¸°
    chart_df["ì¬ê³ íšŒì „ìœ¨"] = chart_df["ì¬ê³ íšŒì „ìœ¨"].fillna(0)
    chart_df["ROA(%)"] = chart_df["ROA(%)"].fillna(0)
    chart_df["ë§¤ì¶œì´ì´ìµ"] = chart_df["ë§¤ì¶œì´ì´ìµ"].fillna(1_000_000_000)
    chart_df["ì¬ê³ ìì‚°"] = chart_df["ì¬ê³ ìì‚°"].fillna(0)
    chart_df["ë§¤ì¶œì•¡"] = chart_df["ë§¤ì¶œì•¡"].fillna(0)

    if chart_df.empty:
        st.warning("4ë¶„ë©´ ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (ì¬ê³ íšŒì „ìœ¨, ROA í•„ìš”)")
        st.write("ì‚¬ì´ë“œë°”ì˜ 'ë‚´ ê°€ê²Œ íŒŒì¼ ë§¤í•‘'ì—ì„œ [ì¬ê³ ìì‚°, ë§¤ì¶œì›ê°€, ë‹¹ê¸°ìˆœì´ìµ, ìì‚°ì´ê³„] ì—´ì´ ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ ë§¤í•‘ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    else:
        # í‰ê· ì€ ì›ë³¸(df_all) ê¸°ì¤€
        x_mean = pd.to_numeric(df_all['ì¬ê³ íšŒì „ìœ¨'], errors='coerce').mean()
        y_mean = pd.to_numeric(df_all['ROA(%)'], errors='coerce').mean()

        x_max_data = pd.to_numeric(chart_df['ì¬ê³ íšŒì „ìœ¨'], errors='coerce').max()
        x_min_data = pd.to_numeric(chart_df['ì¬ê³ íšŒì „ìœ¨'], errors='coerce').min()
        x_min = min(0, x_min_data) - (x_max_data * 0.05)
        x_max = x_max_data * 1.1

        y_max_data = pd.to_numeric(chart_df['ROA(%)'], errors='coerce').max()
        y_min_data = pd.to_numeric(chart_df['ROA(%)'], errors='coerce').min()
        y_min = min(0, y_min_data) - (y_max_data * 0.05)
        y_max = y_max_data * 1.1

        # â‘  ìƒì¥ì‚¬(í•œì„¬ ë“±)ë§Œ ë”°ë¡œ
        api_df = chart_df[chart_df["ë¸Œëœë“œ"] != name2].copy()
        # â‘¡ ë‚´ ê°€ê²Œë§Œ ë”°ë¡œ
        my_df = chart_df[chart_df["ë¸Œëœë“œ"] == name2].copy()

        # ìƒì¥ì‚¬ë§Œ ê¸°ë³¸ ì‚°ì ë„ë¡œ ê·¸ë¦¼ (íŒŒë€ ì ë“¤)
        fig2 = px.scatter(
            api_df,
            x="ì¬ê³ íšŒì „ìœ¨",
            y="ROA(%)",
            color="ë¸Œëœë“œ",
            # size="ë§¤ì¶œì´ì´ìµ",  # â† ì´ ì¤„ ì‚­ì œ
            hover_data=["Year", "ì¬ê³ ìì‚°", "ë§¤ì¶œì•¡"],
            title="íš¨ìœ¨ì„±-ìˆ˜ìµì„± ê´€ê³„ (4ë¶„ë©´ ë¶„ì„)",
            template="plotly_white",
            range_x=[x_min, x_max],
            range_y=[y_min, y_max],
        )

        # ìƒì¥ì‚¬ ì  í¬ê¸° í†µì¼ (ì˜ˆ: 12)
        fig2.update_traces(
            marker=dict(size=16),
            selector=dict(mode="markers")
        )


        # 4ë¶„ë©´ ì˜ì—­ & ê¸°ì¤€ì„ 
        fig2.add_shape(type="rect", layer="below", x0=x_mean, y0=y_mean, x1=x_max, y1=y_max,
                       fillcolor="rgba(110, 200, 110, 0.1)", line_width=0)
        fig2.add_shape(type="rect", layer="below", x0=x_min, y0=y_min, x1=x_mean, y1=y_mean,
                       fillcolor="rgba(200, 110, 110, 0.1)", line_width=0)
        fig2.add_shape(type="rect", layer="below", x0=x_min, y0=y_mean, x1=x_mean, y1=y_max,
                       fillcolor="rgba(200, 200, 200, 0.1)", line_width=0)
        fig2.add_shape(type="rect", layer="below", x0=x_mean, y0=y_min, x1=x_max, y1=y_mean,
                       fillcolor="rgba(200, 200, 200, 0.1)", line_width=0)
        fig2.add_shape(type="line", layer="above", x0=x_mean, y0=y_min, x1=x_mean, y1=y_max,
                       line=dict(color="gray", width=2, dash="dash"))
        fig2.add_shape(type="line", layer="above", x0=x_min, y0=y_mean, x1=x_max, y1=y_mean,
                       line=dict(color="gray", width=2, dash="dash"))

        # ë‚´ ê°€ê²ŒëŠ” overlayë¡œë§Œ, êµµì€ ë¹¨ê°„ ì 
        if not my_df.empty:
            fig2.add_scatter(
                x=my_df["ì¬ê³ íšŒì „ìœ¨"],
                y=my_df["ROA(%)"],
                mode="markers",
                name=f"{name2} (ë‚´ ê°€ê²Œ)",
                marker=dict(
                    color="red",
                    size=16,                 # ìƒì¥ì‚¬(12)ë³´ë‹¤ ì‚´ì§ í¬ê²Œ
                    symbol="circle",
                    line=dict(color="red", width=1.8),
                ),
                hovertext=my_df["Year"],
                showlegend=True,
    )


        st.plotly_chart(fig2, use_container_width=True)

        st.markdown("### ë¸Œëœë“œë³„ ìƒê´€ê³„ìˆ˜ (ì¬ê³ íšŒì „ìœ¨ vs ROA)")
        corr_tbl = (
            chart_df.groupby("ë¸Œëœë“œ")
            .apply(lambda x: round(
                pd.to_numeric(x["ì¬ê³ íšŒì „ìœ¨"], errors='coerce').corr(
                    pd.to_numeric(x["ROA(%)"], errors='coerce')
                ), 3))
            .reset_index(name="ìƒê´€ê³„ìˆ˜")
        )
        st.dataframe(corr_tbl, use_container_width=True)


    with tab1_3:
        st.subheader(f"ì¬ê³ ìì‚° ì˜ˆì¸¡ (í–¥í›„ {forecast_y}ë…„)")
        
        use_log_transform = st.checkbox("ë¡œê·¸ ë³€í™˜(Log Transform) ì‚¬ìš© (ëª¨ë¸ ì•ˆì •í™”)", value=True, 
                                        help="ë°ì´í„° ë³€ë™ì„±ì´ í´ ê²½ìš° ì´ ì˜µì…˜ì„ ì¼œë©´ ì˜ˆì¸¡ ëª¨ë¸ì´ ë” ì•ˆì •í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                                        key="log_transform_model")
        
        # [v4.3] ì°¨íŠ¸ ì‹œê°í™”ìš© ë¡œê·¸ ìŠ¤ì¼€ì¼
        use_log_scale_tab3 = st.checkbox("ë¡œê·¸ ìŠ¤ì¼€ì¼(Log Scale) ì°¨íŠ¸ ì‚¬ìš© (ê·œëª¨ ì°¨ì´ ë¹„êµ)", value=True, 
                                         help="ë‘ íšŒì‚¬ì˜ ì¬ê³  ê·œëª¨ ì°¨ì´ê°€ ë„ˆë¬´ ì»¤ì„œ ì¶”ì„¸ ë¹„êµê°€ ì–´ë ¤ìš¸ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.",
                                         key="log_scale_tab3")
        
        horizon = forecast_y
        fig3 = px.line(title=f"{name1} vs {name2} ì¬ê³ ìì‚° ì˜ˆì¸¡", template="plotly_white")
        has_data = False
        
        # [v4.0] df_allì„ ìˆœíšŒí•˜ë©° ì˜ˆì¸¡
        for nm in df_all["ë¸Œëœë“œ"].unique():
            dfb = df_all[df_all["ë¸Œëœë“œ"] == nm]
            
            ts = dfb[["Date", "ì¬ê³ ìì‚°"]].dropna()
            if len(ts) < 6:
                st.warning(f"âš ï¸ {nm}: Prophet í•™ìŠµì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤(ìµœì†Œ 6 ê´€ì¸¡ í•„ìš”). ì˜ˆì¸¡ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
                
            try:
                df_prophet = ts.rename(columns={"Date": "ds", "ì¬ê³ ìì‚°": "y"})
                
                # [v4.4] Prophetë„ 0ì´ë‚˜ ìŒìˆ˜ ê°’ ì²˜ë¦¬
                if use_log_transform:
                    if (df_prophet['y'] <= 0).any():
                        st.warning(f"âš ï¸ {nm}: ì¬ê³ ìì‚°ì— 0 ë˜ëŠ” ìŒìˆ˜ ê°’ì´ ìˆì–´ Prophet ë¡œê·¸ ë³€í™˜ì„ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        use_log_transform_model = False
                    else:
                        use_log_transform_model = True
                        df_prophet['y'] = np.log(df_prophet['y']) # log1p/expm1 ëŒ€ì‹  log/exp ì‚¬ìš©
                else:
                    use_log_transform_model = False
                
                m = Prophet()
                m.fit(df_prophet) 
                
                fc = m.make_future_dataframe(periods=horizon, freq="Y")
                pred = m.predict(fc)
                
                if use_log_transform_model:
                    pred['yhat'] = np.exp(pred['yhat']) # exp
                    pred['yhat'] = pred['yhat'].clip(lower=0) 

                fig3.add_scatter(x=pred["ds"], y=pred["yhat"], name=f"{nm} (ì˜ˆì¸¡)", line=dict(dash='dot'))
                fig3.add_scatter(x=ts["Date"], y=ts["ì¬ê³ ìì‚°"], mode='lines+markers', name=f"{nm} (ê´€ì¸¡)")
                has_data = True
                
            except Exception as e:
                st.error(f"{nm} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # [v4.3] ë¡œê·¸ ìŠ¤ì¼€ì¼ ì°¨íŠ¸ ì ìš©
        if use_log_scale_tab3:
            # [v4.4] 0 ë˜ëŠ” ìŒìˆ˜ ê°’ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ try-except ì¶”ê°€
            try:
                # 0ë³´ë‹¤ í° ê°’ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                if df_all['ì¬ê³ ìì‚°'].dropna().gt(0).any():
                     fig3.update_layout(yaxis_type="log")
                else:
                    st.warning("ë¡œê·¸ ìŠ¤ì¼€ì¼ì€ ëª¨ë“  ê°’ì´ 0 ë˜ëŠ” ìŒìˆ˜ì´ë¯€ë¡œ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    fig3.update_layout(yaxis_type="linear")
            except Exception:
                 fig3.update_layout(yaxis_type="linear")

        if has_data:
            st.plotly_chart(fig3, use_container_width=True)
        else:
            st.error("ë‘ ê¸°ì—… ëª¨ë‘ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


# --- [v4.0] ìº¡ì…˜ ---
st.markdown("---")
st.caption("Â© 2025 Team 1 | [v4.8] 1:1 ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ì‹œë³´ë“œ (4ë¶„ë©´ Yì¶• ë²„ê·¸ ìˆ˜ì •)")